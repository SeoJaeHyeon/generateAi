{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad02/generalai/generateAi/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        reader = PdfReader(pdf_file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(\"/home/ad02/generalai/generateAi/rag/2023 한국항공대 자율주행 로봇 경진대회 소개.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023한국항공대학교 자율주행 로봇경진대회소개\\n한국항공대학교\\nAI융합대학\\n1Creative Engineering \\nDesign USAR (Urban Search and Rescue)\\n•재해발생후로봇을 사용하여 부분적으로 붕괴된 건물과 같은알수없는환경을\\n탐색하고 재해로 인해갇혔거나 의식을 잃은희생자 또는생존자를 찾는것이필요\\n2\\n•원전이 폭파되어 방사능이 유출된 상황등사람이 접근하지 못하는 환경일 경우\\n•재해전체상황을 빠르게 파악할 필요있음-> 로봇을 이용Creative Engineering \\nDesign USAR Robots\\n3\\nNIST ( National Institute of Standards and Technology) UNSW ( University of New South Wales)Creative Engineering \\nDesign 본대회에서 사용하는 플랫폼 -Turtlebot4\\n4\\nRGB -D Camera\\n2D LiDAR\\n(rplidar )\\nMobile Base ( 모터및구동부 포함 )Single Board Computer\\n(Raspberry Pi 4B)\\nUI보드\\n(터틀봇 상태 , 사용자 버튼 , \\n디스플레이 제공 )Turtlebot4 Tutorial -https://turtlebot.github.io/turtlebot4 -user -manual/Creative Engineering \\nDesign 대회미션\\n•본대회의 미션은 2D 라이다와 RGB-D 카메라가 장착된 Turtlebot4 로봇을\\n사용하여 USAR 문제의 단순화된 버전을 해결하는 것\\n•건물의 벽이나 장애물 -> 미로\\n•희생자 또는생존자 -> 고유한 색상의 비콘또는April Tag, QR code\\n5\\nReference -https://mbanderson.github.io/turtlebot_mission_control/Creative Engineering \\nDesign 대회미션\\n•ROS 기반의 통합된 소프트웨어 (C++ or Python) 을작성하는 것\\n•소프트웨어는 Turtlebot 이다음을 수행할 수있도록 해야함\\n1.터틀봇은 구조를 알수없는공간에 투입되어 탐색합니다 . \\n2.탐색을 하며지도를 구축합니다 . \\n3.\"생존자 \"를찾아구축한 지도에 정확한 위치를 표시합니다 . \\n4.구축한 지도에 로봇이 이동한 경로를 표시합니다 . \\n5.모든\"생존자 \"를찾으면 로봇은 시작위치로 돌아갑니다 . \\n6.이와같은USAR 작업을 최대한 빠르게 완료해야합니다 . 단, 로봇은 완전히 자율적 이어야\\n합니다 . 즉, 로봇이 시작하라는 지시를 받은후에는 (RViz창에서 든Command 창에서 든) \\n수행해야 하는USAR 작업을 완료하고 스스로 멈출때까지 로봇과 상호작용할 수\\n없습니다 . 터틀봇이 원하는 동작을 하지않아프로그램을 종료하고 처음부터 다시\\n시작하는 경우를 제외하고는 팀원의 개입이 없어야 합니다 . \\n6Creative Engineering \\nDesign 평가기준및제출자료\\n•평가의 기준\\n•미션의 완료시간(40점)\\n•\"생존자 \"의위치파악의 정확도 (30점)\\n•탐색하는 동안구축한 지도와 이동한 경로의 퀄리티 (30점)\\n•제출해야 하는자료\\n•작성된 ROS기반소프트웨어를 실행하는 데필요한 모든코드, 실행파일및\\n기타콘텐츠가 포함된 C++ 또는Python 으로작성된 ROS 패키지\\n•미션을 수행하는 동안수집된 실시간 ROS bag 파일\\n•USAR 작업을 어떻게 해결했는지 설명하고 시스템 성능을 분석한 보고서\\n7Creative Engineering \\nDesign 참고자료리스트\\n•Turtlebot4 User manual -https://turtlebot.github.io/turtlebot4 -user-manual/\\n•Turtlebot4 Basic Setup -https://blu -y.github.io/turtle/guide/basic_setup\\n•Turtlebot4 Basic Tutorial1 -https://blu -y.github.io/turtle/guide/basic_tutorial_1\\n•Turtlebot4 Basic Tutorial2 -https://blu -y.github.io/turtle/guide/basic_tutorial_2\\n•Turtlebot4 Image Processing Tutorial -https://blu -y.github.io/turtle/guide/ip_tutorial\\n•References\\n•https://mbanderson.github.io/turtlebot_mission_control/\\n•https://www.nist.gov/news -events/news/2013/06/new -nist-facility -puts-bomb -and-urban-\\nsearch -and-rescue -robots -test\\n•Videos\\n•https://youtu.be/UfT0TUR4S9o\\n•https://youtu.be/5XERzM6ZfJg\\n•https://youtu.be/AamHifhvNMs\\n•https://www.youtube.com/watch?v=VDvcfcSLqLo\\n8'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_by_characters(text, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Splits text into chunks of a specified number of characters.\n",
    "    \"\"\"\n",
    "    nlp_ko = spacy.load(\"en_core_web_md\")\n",
    "    doc = nlp_ko(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in doc:\n",
    "        token_length = len(token.text_with_ws)\n",
    "        if current_length + token_length > chunk_size:\n",
    "            chunks.append(\"\".join(current_chunk).strip())\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "        current_chunk.append(token.text_with_ws)\n",
    "        current_length += token_length\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\"\".join(current_chunk).strip())\n",
    "\n",
    "    return chunks # Sample text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def chunk_text_with_overlap(text, chunk_size=1000, overlap_size=300):\n",
    "    \"\"\"\n",
    "    Splits text into chunks of a specified number of characters with overlap.\n",
    "    \"\"\"\n",
    "    nlp_ko = spacy.load(\"en_core_web_md\")\n",
    "    doc = nlp_ko(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in doc:\n",
    "        token_length = len(token.text_with_ws)\n",
    "        # If the current chunk reaches its size limit, we add it to chunks\n",
    "        if current_length + token_length > chunk_size:\n",
    "            # Add the current chunk to the list\n",
    "            chunks.append(\"\".join(current_chunk).strip())\n",
    "            # Keep the last `overlap_size` characters for the next chunk\n",
    "            overlap_chunk = \"\".join(current_chunk)[-overlap_size:]\n",
    "            # Reset the current chunk and current length\n",
    "            current_chunk = [overlap_chunk]\n",
    "            current_length = len(overlap_chunk)\n",
    "        # Add the token to the current chunk\n",
    "        current_chunk.append(token.text_with_ws)\n",
    "        current_length += token_length\n",
    "\n",
    "    # Add the final chunk if it exists\n",
    "    if current_chunk:\n",
    "        chunks.append(\"\".join(current_chunk).strip())\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "2023한국항공대학교 자율주행 로봇경진대회소개\n",
      "한국항공대학교\n",
      "AI융합대학\n",
      "1Creative Engineering \n",
      "Design USAR (Urban Search and Rescue)\n",
      "•재해발생후로봇을 사용하여 부분적으로 붕괴된 건물과 같은알수없는환경을\n",
      "탐색하고 재해로 인해갇혔거나 의식을 잃은희생자 또는생존자를 찾는것이필요\n",
      "2\n",
      "•원전이 폭파되어 방사능이 유출된 상황등사람이 접근하지 못하는 환경일 경우\n",
      "•재해전체상황을 빠르게 파악할 필요있음-> 로봇을 이용Creative Engineering \n",
      "Design USAR Robots\n",
      "3\n",
      "NIST ( National Institute of Standards and Technology) UNSW ( University of New South Wales)Creative Engineering \n",
      "Design 본대회에서 사용하는 플랫폼 -Turtlebot4\n",
      "4\n",
      "RGB -D Camera\n",
      "2D LiDAR\n",
      "(rplidar )\n",
      "Mobile Base (\n",
      "\n",
      "Chunk 2:\n",
      "3\n",
      "NIST ( National Institute of Standards and Technology) UNSW ( University of New South Wales)Creative Engineering \n",
      "Design 본대회에서 사용하는 플랫폼 -Turtlebot4\n",
      "4\n",
      "RGB -D Camera\n",
      "2D LiDAR\n",
      "(rplidar )\n",
      "Mobile Base ( 모터및구동부 포함 )Single Board Computer\n",
      "(Raspberry Pi 4B)\n",
      "UI보드\n",
      "(터틀봇 상태 , 사용자 버튼 , \n",
      "디스플레이 제공 )Turtlebot4 Tutorial -https://turtlebot.github.io/turtlebot4 -user -manual/Creative Engineering \n",
      "Design 대회미션\n",
      "•본대회의 미션은 2D 라이다와 RGB-D 카메라가 장착된 Turtlebot4 로봇을\n",
      "사용하여 USAR 문제의 단순화된 버전을 해결하는 것\n",
      "•건물의 벽이나 장애물 -> 미로\n",
      "•희생자\n",
      "\n",
      "Chunk 3:\n",
      "Tutorial -https://turtlebot.github.io/turtlebot4 -user -manual/Creative Engineering \n",
      "Design 대회미션\n",
      "•본대회의 미션은 2D 라이다와 RGB-D 카메라가 장착된 Turtlebot4 로봇을\n",
      "사용하여 USAR 문제의 단순화된 버전을 해결하는 것\n",
      "•건물의 벽이나 장애물 -> 미로\n",
      "•희생자 또는생존자 -> 고유한 색상의 비콘또는April Tag, QR code\n",
      "5\n",
      "Reference -https://mbanderson.github.io/turtlebot_mission_control/Creative Engineering \n",
      "Design 대회미션\n",
      "•ROS 기반의 통합된 소프트웨어 (C++ or Python) 을작성하는 것\n",
      "•소프트웨어는 Turtlebot 이다음을 수행할 수있도록 해야함\n",
      "1.터틀봇은 구조를 알수없는공간에 투입되어 탐색합니다 . \n",
      "2.탐색을 하며지도를 구축합니다 . \n",
      "3.\"생존자 \"를찾아구축한 지도에 정확한\n",
      "\n",
      "Chunk 4:\n",
      "n_control/Creative Engineering \n",
      "Design 대회미션\n",
      "•ROS 기반의 통합된 소프트웨어 (C++ or Python) 을작성하는 것\n",
      "•소프트웨어는 Turtlebot 이다음을 수행할 수있도록 해야함\n",
      "1.터틀봇은 구조를 알수없는공간에 투입되어 탐색합니다 . \n",
      "2.탐색을 하며지도를 구축합니다 . \n",
      "3.\"생존자 \"를찾아구축한 지도에 정확한 위치를 표시합니다 . \n",
      "4.구축한 지도에 로봇이 이동한 경로를 표시합니다 . \n",
      "5.모든\"생존자 \"를찾으면 로봇은 시작위치로 돌아갑니다 . \n",
      "6.이와같은USAR 작업을 최대한 빠르게 완료해야합니다 . 단, 로봇은 완전히 자율적 이어야\n",
      "합니다 . 즉, 로봇이 시작하라는 지시를 받은후에는 (RViz창에서 든Command 창에서 든) \n",
      "수행해야 하는USAR 작업을 완료하고 스스로 멈출때까지 로봇과 상호작용할 수\n",
      "없습니다 . 터틀봇이 원하는 동작을 하지않아프로그램을 종료하고 처음부터 다시\n",
      "시작하는 경우를 제외하고는 팀원의 개입이 없어야\n",
      "\n",
      "Chunk 5:\n",
      "르게 완료해야합니다 . 단, 로봇은 완전히 자율적 이어야\n",
      "합니다 . 즉, 로봇이 시작하라는 지시를 받은후에는 (RViz창에서 든Command 창에서 든) \n",
      "수행해야 하는USAR 작업을 완료하고 스스로 멈출때까지 로봇과 상호작용할 수\n",
      "없습니다 . 터틀봇이 원하는 동작을 하지않아프로그램을 종료하고 처음부터 다시\n",
      "시작하는 경우를 제외하고는 팀원의 개입이 없어야 합니다 . \n",
      "6Creative Engineering \n",
      "Design 평가기준및제출자료\n",
      "•평가의 기준\n",
      "•미션의 완료시간(40점)\n",
      "•\"생존자 \"의위치파악의 정확도 (30점)\n",
      "•탐색하는 동안구축한 지도와 이동한 경로의 퀄리티 (30점)\n",
      "•제출해야 하는자료\n",
      "•작성된 ROS기반소프트웨어를 실행하는 데필요한 모든코드, 실행파일및\n",
      "기타콘텐츠가 포함된 C++ 또는Python 으로작성된 ROS 패키지\n",
      "•미션을 수행하는 동안수집된 실시간 ROS bag 파일\n",
      "•USAR 작업을 어떻게 해결했는지 설명하고 시스템 성능을 분석한 보고서\n",
      "7Creative\n",
      "\n",
      "Chunk 6:\n",
      "는 동안구축한 지도와 이동한 경로의 퀄리티 (30점)\n",
      "•제출해야 하는자료\n",
      "•작성된 ROS기반소프트웨어를 실행하는 데필요한 모든코드, 실행파일및\n",
      "기타콘텐츠가 포함된 C++ 또는Python 으로작성된 ROS 패키지\n",
      "•미션을 수행하는 동안수집된 실시간 ROS bag 파일\n",
      "•USAR 작업을 어떻게 해결했는지 설명하고 시스템 성능을 분석한 보고서\n",
      "7Creative Engineering \n",
      "Design 참고자료리스트\n",
      "•Turtlebot4 User manual -https://turtlebot.github.io/turtlebot4 -user-manual/\n",
      "•Turtlebot4 Basic Setup -https://blu -y.github.io/turtle/guide/basic_setup\n",
      "•Turtlebot4 Basic Tutorial1 -https://blu -y.github.io/turtle/guide/basic_tutorial_1\n",
      "•Turtlebot4 Basic Tutorial2\n",
      "\n",
      "Chunk 7:\n",
      "user-manual/\n",
      "•Turtlebot4 Basic Setup -https://blu -y.github.io/turtle/guide/basic_setup\n",
      "•Turtlebot4 Basic Tutorial1 -https://blu -y.github.io/turtle/guide/basic_tutorial_1\n",
      "•Turtlebot4 Basic Tutorial2 -https://blu -y.github.io/turtle/guide/basic_tutorial_2\n",
      "•Turtlebot4 Image Processing Tutorial -https://blu -y.github.io/turtle/guide/ip_tutorial\n",
      "•References\n",
      "•https://mbanderson.github.io/turtlebot_mission_control/\n",
      "•https://www.nist.gov/news -events/news/2013/06/new -nist-facility -puts-bomb -and-\n",
      "\n",
      "Chunk 8:\n",
      "tps://blu -y.github.io/turtle/guide/ip_tutorial\n",
      "•References\n",
      "•https://mbanderson.github.io/turtlebot_mission_control/\n",
      "•https://www.nist.gov/news -events/news/2013/06/new -nist-facility -puts-bomb -and-urban-\n",
      "search -and-rescue -robots -test\n",
      "•Videos\n",
      "•https://youtu.be/UfT0TUR4S9o\n",
      "•https://youtu.be/5XERzM6ZfJg\n",
      "•https://youtu.be/AamHifhvNMs\n",
      "•https://www.youtube.com/watch?v=VDvcfcSLqLo\n",
      "8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the chunks\n",
    "chunks = chunk_text_with_overlap(text,500, 200)\n",
    "\n",
    "# Display the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Sentence Transformers model\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# # Generate embeddings\n",
    "# embeddings = model.encode(chunks)\n",
    "\n",
    "# # Output embeddings\n",
    "# for i, chunk in enumerate(chunks):\n",
    "#     print(f\"Chunk: {chunk}\")\n",
    "#     print(f\"Embedding: {embeddings[i][:5]}...\")  # Displaying first 5 dimensions for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the embeddings: 768\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the corpus\n",
    "corpus_embeddings = model.encode(chunks)\n",
    "\n",
    "\n",
    "# Initialize a FAISS index\n",
    "dimension = corpus_embeddings.shape[1]\n",
    "print(f\"Dimension of the embeddings: {dimension}\")\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance metric\n",
    "index.add(corpus_embeddings)  # Add embeddings to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query\n",
    "# query = \"Where is the Eiffel Tower located?\"\n",
    "ko_query = \"언제 대회가 시작됩니까?\"\n",
    "query_embedding = model.encode([ko_query])\n",
    "\n",
    "# Perform similarity search\n",
    "k = 3  # Number of nearest neighbors to retrieve\n",
    "distances, indices = index.search(query_embedding, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[12.333832, 13.250383, 13.480976]], dtype=float32), array([[2, 1, 0]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Chunk 1: ative Engineering \n",
      "Design 평가기준및제출자료\n",
      "•평가의 기준\n",
      "•미션의 완료시간(40점)\n",
      "•\"생존자 \"의위치파악의 정확도 (30점)\n",
      "•탐색하는 동안구축한 지도와 이동한 경로의 퀄리티 (30점)\n",
      "•제출해야 하는자료\n",
      "•작성된 ROS기반소프트웨어를 실행하는 데필요한 모든코드, 실행파일및\n",
      "기타콘텐츠가 포함된 C++ 또는Python 으로작성된 ROS 패키지\n",
      "•미션을 수행하는 동안수집된 실시간 ROS bag 파일\n",
      "•USAR 작업을 어떻게 해결했는지 설명하고 시스템 성능을 분석한 보고서\n",
      "7Creative Engineering \n",
      "Design 참고자료리스트\n",
      "•Turtlebot4 User manual -https://turtlebot.github.io/turtlebot4 -user-manual/\n",
      "•Turtlebot4 Basic Setup -https://blu -y.github.io/turtle/guide/basic_setup\n",
      "•Turtlebot4 Basic Tutorial1 -https://blu -y.github.io/turtle/guide/basic_tutorial_1\n",
      "•Turtlebot4 Basic Tutorial2 -https://blu -y.github.io/turtle/guide/basic_tutorial_2\n",
      "•Turtlebot4 Image Processing Tutorial -https://blu -y.github.io/turtle/guide/ip_tutorial\n",
      "•References\n",
      "•https://mbanderson.github.io/turtlebot_mission_control/\n",
      "•https://www.nist.gov/news -events/news/2013/06/new -nist-facility -puts-bomb -and-urban-\n",
      "search -and-rescue -robots -test\n",
      "•Videos\n",
      "•https://youtu.be/UfT0TUR4S9o\n",
      "•https://youtu.be/5XERzM6ZfJg\n",
      "\n",
      "Retrieved Chunk 2: 2D 라이다와 RGB-D 카메라가 장착된 Turtlebot4 로봇을\n",
      "사용하여 USAR 문제의 단순화된 버전을 해결하는 것\n",
      "•건물의 벽이나 장애물 -> 미로\n",
      "•희생자 또는생존자 -> 고유한 색상의 비콘또는April Tag, QR code\n",
      "5\n",
      "Reference -https://mbanderson.github.io/turtlebot_mission_control/Creative Engineering \n",
      "Design 대회미션\n",
      "•ROS 기반의 통합된 소프트웨어 (C++ or Python) 을작성하는 것\n",
      "•소프트웨어는 Turtlebot 이다음을 수행할 수있도록 해야함\n",
      "1.터틀봇은 구조를 알수없는공간에 투입되어 탐색합니다 . \n",
      "2.탐색을 하며지도를 구축합니다 . \n",
      "3.\"생존자 \"를찾아구축한 지도에 정확한 위치를 표시합니다 . \n",
      "4.구축한 지도에 로봇이 이동한 경로를 표시합니다 . \n",
      "5.모든\"생존자 \"를찾으면 로봇은 시작위치로 돌아갑니다 . \n",
      "6.이와같은USAR 작업을 최대한 빠르게 완료해야합니다 . 단, 로봇은 완전히 자율적 이어야\n",
      "합니다 . 즉, 로봇이 시작하라는 지시를 받은후에는 (RViz창에서 든Command 창에서 든) \n",
      "수행해야 하는USAR 작업을 완료하고 스스로 멈출때까지 로봇과 상호작용할 수\n",
      "없습니다 . 터틀봇이 원하는 동작을 하지않아프로그램을 종료하고 처음부터 다시\n",
      "시작하는 경우를 제외하고는 팀원의 개입이 없어야 합니다 . \n",
      "6Creative Engineering \n",
      "Design 평가기준및제출자료\n",
      "•평가의 기준\n",
      "•미션의 완료시간(40점)\n",
      "•\"생존자 \"의위치파악의 정확도 (30점)\n",
      "•탐색하는 동안구축한 지도와 이동한 경로의 퀄리티 (30점)\n",
      "•제출해야 하는자료\n",
      "•작성된 ROS기반소프트웨어를 실행하는 데필요한 모든코드, 실행파일및\n",
      "기타콘텐츠가 포함된 C++ 또는Python 으로작성된 ROS 패키지\n",
      "•미션을 수행하는 동안수집된 실시간 ROS bag 파일\n",
      "•USAR 작업을 어떻게 해결했는지 설명하고 시스템 성능을 분석한 보고서\n",
      "7Creative Engineering\n",
      "\n",
      "Retrieved Chunk 3: 2023한국항공대학교 자율주행 로봇경진대회소개\n",
      "한국항공대학교\n",
      "AI융합대학\n",
      "1Creative Engineering \n",
      "Design USAR (Urban Search and Rescue)\n",
      "•재해발생후로봇을 사용하여 부분적으로 붕괴된 건물과 같은알수없는환경을\n",
      "탐색하고 재해로 인해갇혔거나 의식을 잃은희생자 또는생존자를 찾는것이필요\n",
      "2\n",
      "•원전이 폭파되어 방사능이 유출된 상황등사람이 접근하지 못하는 환경일 경우\n",
      "•재해전체상황을 빠르게 파악할 필요있음-> 로봇을 이용Creative Engineering \n",
      "Design USAR Robots\n",
      "3\n",
      "NIST ( National Institute of Standards and Technology) UNSW ( University of New South Wales)Creative Engineering \n",
      "Design 본대회에서 사용하는 플랫폼 -Turtlebot4\n",
      "4\n",
      "RGB -D Camera\n",
      "2D LiDAR\n",
      "(rplidar )\n",
      "Mobile Base ( 모터및구동부 포함 )Single Board Computer\n",
      "(Raspberry Pi 4B)\n",
      "UI보드\n",
      "(터틀봇 상태 , 사용자 버튼 , \n",
      "디스플레이 제공 )Turtlebot4 Tutorial -https://turtlebot.github.io/turtlebot4 -user -manual/Creative Engineering \n",
      "Design 대회미션\n",
      "•본대회의 미션은 2D 라이다와 RGB-D 카메라가 장착된 Turtlebot4 로봇을\n",
      "사용하여 USAR 문제의 단순화된 버전을 해결하는 것\n",
      "•건물의 벽이나 장애물 -> 미로\n",
      "•희생자 또는생존자 -> 고유한 색상의 비콘또는April Tag, QR code\n",
      "5\n",
      "Reference -https://mbanderson.github.io/turtlebot_mission_control/Creative Engineering \n",
      "Design 대회미션\n",
      "•ROS 기반의 통합된 소프트웨어 (C++ or Python) 을작성하는 것\n",
      "•소프트웨어는 Turtlebot 이다음을\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and display results\n",
    "retrieved_chunks = [chunks[idx] for idx in indices[0]]\n",
    "for i, chunk in enumerate(retrieved_chunks):\n",
    "    print(f\"Retrieved Chunk {i+1}: {chunk}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
