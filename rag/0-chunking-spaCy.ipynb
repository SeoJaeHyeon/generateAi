{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. install spacy   \n",
    "2. python -m spacy download ko_core_news_md (ko_core_news_sm, ko_core_news_lg)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the spaCy model en_core_web_md and ko_core_news_md\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp_ko = spacy.load(\"ko_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunking of single string of text by sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a sentence in English.', '이것은 한국어로 된 문장입니다.', 'This is another sentence in English.']\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a sentence in English. 이것은 한국어로 된 문장입니다. This is another sentence in English.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "def chunk_text_by_sentence(doc):\n",
    "    return [sent.text for sent in doc.sents]\n",
    "\n",
    "print(chunk_text_by_sentence(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.']\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Natural language processing (NLP) is a subfield of linguistics, computer science, \"\n",
    "    \"and artificial intelligence concerned with the interactions between computers and human language, \"\n",
    "    \"in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
    ")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(chunk_text_by_sentence(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial\n",
      "\n",
      "Chunk 2:\n",
      "intelligence concerned with the interactions between computers and human language, in particular\n",
      "\n",
      "Chunk 3:\n",
      "how to program computers to process and analyze large amounts of natural language data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chunk_text_by_characters(text, chunk_size):\n",
    "    \"\"\"\n",
    "    Splits text into chunks of a specified number of characters.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in doc:\n",
    "        token_length = len(token.text_with_ws)\n",
    "        if current_length + token_length > chunk_size:\n",
    "            chunks.append(\"\".join(current_chunk).strip())\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "        current_chunk.append(token.text_with_ws)\n",
    "        current_length += token_length\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\"\".join(current_chunk).strip())\n",
    "\n",
    "    return chunks# Sample text\n",
    "\n",
    "text = (\n",
    "    \"Natural language processing (NLP) is a subfield of linguistics, computer science, \"\n",
    "    \"and artificial intelligence concerned with the interactions between computers and human language, \"\n",
    "    \"in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
    ")\n",
    "\n",
    "# Define the desired chunk size in characters\n",
    "chunk_size = 100\n",
    "\n",
    "# Get the chunks\n",
    "chunks = chunk_text_by_characters(text, chunk_size)\n",
    "\n",
    "# Display the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\\n{chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunking of list of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of texts to process\n",
    "texts = [\n",
    "    \"This is the first document.\",\n",
    "    \"Here is the second one.\",\n",
    "    \"And this is the third document.\",\n",
    "    \"한글 문장입니다.\",\n",
    "    \"문장이 길면 sentence를 분할해주나요?\",\n",
    "]\n",
    "\n",
    "\n",
    "def chunk_texts_by_sentence(docs):\n",
    "\n",
    "    return [chunk_text_by_sentence(doc) for doc in docs]\n",
    "\n",
    "def chunk_texts_by_characters(docs, chunk_size):\n",
    "    \n",
    "    return [chunk_text_by_characters(doc, chunk_size) for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process texts in batches\n",
    "docs = nlp_ko.pipe(texts)\n",
    "chunks = chunk_texts_by_sentence(docs)\n",
    "print(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process texts in batches\n",
    "docs = nlp_ko.pipe(texts)\n",
    "chunks = chunk_texts_by_characters(docs, chunk_size=10)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
